# ğŸ¤– RAG Chatbot (Retrieval-Augmented Generation)

A **RAG-based AI chatbot** that combines **intelligent document retrieval** with **LLM reasoning** to deliver accurate, context-aware answers grounded in custom data.

---

## ğŸ“Œ Overview

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline where user queries are first enriched with relevant context retrieved from a document store and then passed to a Large Language Model for precise response generation.

The chatbot is designed to reduce hallucinations by ensuring responses are backed by real, retrieved data.

Functional UI Screenshot
<img width="1680" height="957" alt="image" src="answer.png" />
<img width="1680" height="957" alt="image" src="uploadoption.png" />

---

## âœ¨ Features

- Intelligent document retrieval using embeddings  
- Context-aware answers grounded in custom documents  
- Integration with LLM API for natural language responses  
- Fast and scalable architecture  
- Clean backend pipeline for data ingestion, embedding, and querying  
- Easy to extend with new documents  

---

## ğŸ—ï¸ Tech Stack

- **Programming Language:** Python  
- **LLM:** API-based Large Language Model  
- **Vector Database:** ChromaDB  
- **Embeddings:** Text / sentence embeddings  
- **Backend:** Python  
- **Frontend:** Simple web-based UI  

---

## ğŸ“‚ Project Structure

```
RAG-Chatbot/
â”‚â”€â”€ data/                 # Sample documents (PDF / text)
â”‚â”€â”€ chroma_db/            # Vector database (local)
â”‚â”€â”€ ui/                   # Frontend files
â”‚â”€â”€ requirements.txt      # Project dependencies
â”‚â”€â”€ .gitignore
â”‚â”€â”€ main.py / app.py      # Application entry point
```

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Nik-99WEB/RAG-Chatbot.git
cd RAG-Chatbot
```

### 2ï¸âƒ£ Create & activate virtual environment
```bash
python -m venv venv
source venv/Scripts/activate   # Windows (Git Bash)
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set environment variables
Create a `.env` file in the project root:
```env
API_KEY=your_api_key_here
```

> âš ï¸ Do not upload `.env` to GitHub.

---

### 5ï¸âƒ£ Run the chatbot
```bash
python main.py
```

---

## ğŸ§  How It Works

1. Documents are ingested and converted into embeddings  
2. Embeddings are stored in a vector database  
3. User queries are embedded and matched with relevant documents  
4. Retrieved context is passed to the LLM  
5. The LLM generates a grounded, accurate response  

---

## ğŸš€ Use Cases

- Document-based Question Answering  
- Internal knowledge assistants  
- AI-powered customer support  
- Research and study assistants  

---

## ğŸ“Œ Future Improvements

- Authentication & user management  
- Improved UI/UX  
- Support for multiple document uploads  
- Cloud deployment (AWS / GCP / Vercel)  

---

## ğŸ‘¤ Author

**Nikhil Kumar Jaiswal**  

Built as a learning-focused AI project to understand **LLM + Retrieval-Augmented Generation (RAG)** architecture.

---

â­ If you find this project useful, feel free to star the repository!
